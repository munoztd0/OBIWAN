#' Calculate free energy for the approximate posterior
#'
#' This function derives the free energy for the current approximate posterior. This routine has been translated from the VBA_groupBMC function of the VBA toolbox http://code.google.com/p/mbb-vb-toolbox/ which was written by Lionel Rigoux and J. Daunizeau. See equation A.20 in Rigoux et al. (should be F1 on LHS)
#' @param m N by K (N subjects by K models) matrix of log-model evidence.
#' @param alpha Dirichlet parameters (usually the posterior estimate).
#' @param g N by K (N subjects by K models) matrix of normalized posterior beliefs.
#' @return Free energy (evidence in favor of different model frequencies).
#' @export
#' 
#'
#' 

repmat <- function(X,m,n){
  mx = dim(X)[1]
  nx = dim(X)[2]
  matrix(t(matrix(X,mx,nx*n)),mx*m,nx*n,byrow=T)
}

dirichlet_exceedance <- function(alpha, Nsamp=1e6){
Nk <- length(alpha)
ind_max <- function(x) ifelse(x==max(x),1,0)
xp <- rep(0,Nk)

# Sample from univariate gamma densities then normalise
# (see Dirichlet entry in Wikipedia or Ferguson (1973) Ann. Stat. 1,
#   % 209-230)
r = repmat(as.matrix(0), Nsamp, Nk)

for(k in 1:Nk){
  r[,k] <- rgamma(Nsamp, alpha[k], scale = 1)
}
sr <- apply(r,1,sum)

for(k in 1:Nk){
  r[,k] <- r[,k]/sr
}

# Exceedance probabilities:
# For any given model k1, compute the probability that it is more
# likely than any other model k2~=k1
j <- apply(r, 1, which.max)
# xp <- xp + unname(tapply(j, factor(j),length)) # old
label_j <- factor(j, levels=1:Nk)
xp <- xp + unname(tapply(j, label_j,length))

# if there's any model which was never the most frequent
# then it's value would turn out to be NA here
# so I cahnge it to zero
xp <- ifelse(is.na(xp),0,xp)
xp <-xp/Nsamp
}

FE <- function(m, a, g){
  n <- dim(m)[1]  # number of subjects
  K <- dim(m)[2]  # number of models
  a0 <- rep(1, K)
  Elogr <- digamma(a)- digamma(sum(a))
  Sqf <- sum(lgamma(a)) - lgamma(sum(a)) - sum((a-1)*Elogr)
  Sqm <- 0
  for(i in 1:n){
    Sqm <- Sqm - sum(g[i,] * log(g[i,]+.Machine$double.eps))
  }
  ELJ <- lgamma(sum(a0)) - sum(lgamma(a0)) + sum((a0-1)*Elogr)
  for(i in 1:n){
    for(k in 1:K){
      ELJ <- ELJ + g[i,k]*(Elogr[k]+m[i,k])
    }
  }
  F_ <- ELJ + Sqf + Sqm
  return(F_)
}

FE_null <- function(m){
  n <- dim(m)[1]  # number of subjects
  K <- dim(m)[2]  # number of models
  F0m <- 0
  for(i in 1:n){
    tmp <- m[i,] - max(m[i,])
    g <- exp(tmp)/sum(exp(tmp))
    for(k in 1:K){
      F0m = F0m + g[k] * (m[i,k]-log(K)-log(g[k]+.Machine$double.eps))
    }
  }
  return(unname(F0m))
}

VB_bms <-function(m, n_samples=1e6){
  
  max_val <- log(.Machine$double.xmax)
  Ni      <- dim(m)[1]  # number of subjects
  Nk      <- dim(m)[2]  # number of models
  c       <- 1
  cc      <- 10e-4
  # norm_vec <- function(x) sqrt(sum(x^2))
  
  alpha0 <- rep(1, Nk)
  
  log_u <- matrix(NA,dim(m)[1],dim(m)[2])
  u <- matrix(NA,dim(m)[1],dim(m)[2])
  g <- matrix(NA,dim(m)[1],dim(m)[2])
  alpha <- alpha0
  beta <- rep(NA,Nk)
  
  # iterative VB estimation
  while(c > cc){
    for(i in 1:Ni){
      for(k in 1:Nk){
        # integrate out prior probabilities of models (in log space)
        log_u[i,k] <- m[i,k] + digamma(alpha[k])- digamma(sum(alpha))
      }
      # prevent numerical problems for badly scaled posteriors
      for(k in 1:Nk){
        log_u[i,k] <- sign(log_u[i,k]) * min(max_val, abs(log_u[i,k]))
      }
      
      # exponentiate (to get back to non-log representation)
      u[i,]  <- exp(log_u[i,])
      
      # normalisation: sum across all models for i-th subject
      u_i  <- sum(u[i,])
      g[i,] <- u[i,]/u_i
    }
    
    # expected number of subjects whose data we believe to have been 
    # generated by model k
    for(k in 1:Nk){
      beta[k] <- sum(g[,k]) 
    }
    
    # update alpha
    prev  <- alpha
    for(k in 1:Nk){
      alpha[k] <- alpha0[k] + beta[k]
    }
    
    # convergence?
    c <- sqrt(sum((alpha - prev)^2))
    
  }
  
  # the posterior p(r|y)
  exp_r <- alpha/sum(alpha)
  
  # exceedance probabilities
  xp <- dirichlet_exceedance(alpha,n_samples)
  
  # Bayes Omnibus Risk and Preotected xp
  F1 <- FE(m, alpha , g) # Evidence of alternative
  F0 <- FE_null(m) # Evidence of null (equal model freqs)
  
  # Implied by Eq 5 (see also p39) in Rigoux et al.
  # See also, last equation in Appendix 2
  bor <- 1/(1+exp(F1-F0))
  
  # Compute protected exceedance probs - Eq 7 in Rigoux et al.
  pxp <- (1-bor)*xp+bor/Nk
  
  # output
  return(list(alpha=alpha, r=exp_r, xp=xp, bor=bor, pxp=pxp))
  
}