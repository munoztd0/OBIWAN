}
data$reward = as.numeric(data$reward)
data$type = revalue(data$type, c(AB=12, CD=34, EF=56))
data$type = as.numeric(as.character(data$type))
bs = ddply(data, .(Subject, Session, imcor), summarise, acc = mean(Stim.ACC, na.rm = TRUE))
# Crtierium chose A at 65%, C at 60% and E at 50% and min 30 trials.
bs_wide <- spread(bs, imcor, acc)
bs_wide$pass = c(1:length(bs_wide$Subject)) #initialize variable
for (i in  1:length(bs_wide$Subject)) {
if((bs_wide$A[i] >= 0.65) && (bs_wide$C[i] >=  0.60) && (bs_wide$E[i] >= 0.50 ))
{bs_wide$pass[i] = 1}
else {bs_wide$pass[i] = 0}
}
data = merge(data, bs_wide[ , c("Subject", "pass")], by = "Subject", all.x=TRUE)
data = subset(data, pass == 1)
dataclean <- select(data, c(subjID, type, choice, reward, Session, intervention))
count_trial = dataclean %>% group_by(subjID, Session, type) %>%tally()
df = tally(group_by(dataclean, subjID, Session, intervention))
densityPlot(df$n)
View(df)
bf = ttestBF(formula = n ~ Group* intervention, data = df)
bf <- recompute(bf, iterations = 50000)
bf
bf = ttestBF(formula = n ~ Session* intervention, data = df)
bf <- recompute(bf, iterations = 50000)
bf
bf = ttestBF(formula = n ~ Session*intervention, data = df)
bf = anovaBF(formula = n ~ Session*intervention, data = df)
bf = anovaBF( n ~ Session*intervention, whichRandom =  subjID, data = df)
BF <- anovaBF(n ~ Session*intervention  + id, data = df,
whichRandom = "subjID", iterations = 50000)
BF <- anovaBF(n ~ Session*intervention  + subjID, data = df,
whichRandom = "subjID", iterations = 50000)
fac <- c("subjID", "Session", "intervention")
df[fac] <- lapply(df[fac], factor)
#bayesian
BF <- anovaBF(n ~ Session*intervention  + subjID, data = df,
whichRandom = "subjID", iterations = 50000)
bf <- recompute(bf, iterations = 50000)
bf
BF
plot(BF)
frqaov <- aov_car(n ~ Session*intervention + Error (id/Session), data = df, anova_table = list(correction = "GG", es = "pes"))
library(afex)
frqaov <- aov_car(n ~ Session*intervention + Error (id/Session), data = df, anova_table = list(correction = "GG", es = "pes"))
frqaov <- aov_car(n ~ Session*intervention + Error (subjID/Session), data = df, anova_table = list(correction = "GG", es = "pes"))
frqaov
## R code for FOR PROBA LEARNING TASK OBIWAN
# last modified on April 2020 by David MUNOZ TORD
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE))
# PRELIMINARY STUFF ----------------------------------------
if(!require(pacman)) {
install.packages("pacman")
library(pacman)
}
pacman::p_load(tidyverse, plyr,dplyr,readr, car, BayesFactor, tidyBF, sjmisc, afex)
#options(mc.cores = parallel::detectCores()) #to mulithread
#install.packages("~/Desktop/hBayesDM.tar.xz", repos = NULL) # your need to install this modfied version of hBayesDM where I implement a model of the PST task with one learning rate
#library(hBayesDM) #again only load after your installed my version of hBayesDM
# SETUP ------------------------------------------------------------------
task = 'PBlearning'
# Set working directory #change here if the switchdrive is not on your home folder
analysis_path <- file.path('~/OBIWAN/DERIVATIVES/BEHAV')
figures_path  <- file.path('~/OBIWAN/DERIVATIVES/FIGURES/BEHAV')
setwd(analysis_path)
# open dataset
full <- read_csv(file.path(analysis_path, "PBLearning.csv"), col_types = cols(Subject = col_integer()))
info <- read.delim(file.path(analysis_path,'info_expe.txt'), header = T, sep ='') # read in dataset
info$Subject = info$id
# Preprocess --------------------------------------------------------------
data  <- subset(full, Group == 'O') #subset #only session one
data  <- subset(data, Phase == 'proc1') #only learning phase
#recode participants
for (i in  1:length(data$Subject)) {
if(data$Subject[i] == 2251) #fix the bug
{data$Subject[i] = 245}
else if(data$Subject[i] == 2512210)
{data$Subject[i] = 251}
else if(data$Subject[i] > 2000)
{data$Subject[i] = data$Subject[i] - 2000}
else
{data$Subject[i] = data$Subject[i]}
}
View(data)
data = merge(data, info, by = "Subject")
#factorize and rename
data$type = as.factor(revalue(data$imcor, c(A="AB", C="CD", E="EF")))
data$reward = revalue(data$feedback, c(Negatif=0, Positif=1))
data$side = revalue(data$Stim.RESP, c(x='L', n='R'))
data$subjID = data$Subject
#This loop is there to transform everything into one column "choice"
#this column takes a 1 if the action was to choose either A, C or E
#and takes 0 if the response is either B, D or F (and that independently of the side)
data$choice = c(1:length(data$Trial)) #initialize variable
for (i in  1:length(data$Trial)) {
if((data$side[i] == 'L')&(data$img[i] == 'A' || data$img[i] == 'C' || data$img[i] == 'E'))
{data$choice[i] = 1}
else if ((data$side[1] == 'R')&(data$imd[i] == 'A' || data$imd[i] == 'C' || data$imd[i] == 'E'))
{data$choice[i] = 1}
else
{data$choice[i] = 0}
}
data$reward = as.numeric(data$reward)
data$type = revalue(data$type, c(AB=12, CD=34, EF=56))
data$type = as.numeric(as.character(data$type))
bs = ddply(data, .(Subject, Session, imcor), summarise, acc = mean(Stim.ACC, na.rm = TRUE))
# Crtierium chose A at 65%, C at 60% and E at 50% and min 30 trials.
bs_wide <- spread(bs, imcor, acc)
bs_wide$pass = c(1:length(bs_wide$Subject)) #initialize variable
for (i in  1:length(bs_wide$Subject)) {
if((bs_wide$A[i] >= 0.65) && (bs_wide$C[i] >=  0.60) && (bs_wide$E[i] >= 0.50 ))
{bs_wide$pass[i] = 1}
else {bs_wide$pass[i] = 0}
}
data = merge(data, bs_wide[ , c("Subject", "pass")], by = "Subject", all.x=TRUE)
data = subset(data, pass == 1)
dataclean <- select(data, c(subjID, type, choice, reward, Session, intervention))
count_trial = dataclean %>% group_by(subjID, Session, type) %>%tally()
# Time to acquire reach criterium -----------------------------------------------------
df = tally(group_by(dataclean, subjID, Session, intervention))
densityPlot(df$n)
fac <- c("subjID", "Session", "intervention")
df[fac] <- lapply(df[fac], factor)
#bayesian
BF <- anovaBF(n ~ Session*intervention  + subjID, data = df,
whichRandom = "subjID", iterations = 50000)
BF; plot(BF)
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, session == 'second'))
####################################################################################################
#                                                                                                  #
#                                                                                                  # #                                                                                                  #
#                                    TITLE OF THE PAPER                                            #
#                                                                                                  #
#                                                                                                  #
#                                                                                                  #
# Created by E.R.P on NOVEMBER 2018                                                               #
# modified by D.M.T. on AUGUST 2020                                                                 #
####################################################################################################
#--------------------------------------  PRELIMINARY STUFF ----------------------------------------
#load libraries
if(!require(pacman)) {
install.packages("pacman")
library(pacman)
}
pacman::p_load(apaTables, MBESS, afex, car, ggplot2, dplyr, plyr, tidyr,
reshape, Hmisc, Rmisc,  ggpubr, ez, gridExtra, plotrix,
lsmeans, BayesFactor, effectsize, devtools, misty)
if(!require(devtools)) {
install.packages("devtools")
library(devtools)
}
# get tool
devtools::source_gist("2a1bb0133ff568cbe28d",
filename = "geom_flat_violin.R")
#SETUP
# Set path
home_path       <- '~/OBIWAN'
# Set working directory
analysis_path <- file.path(home_path, 'CODE/ANALYSIS/BEHAV/ForPaper')
figures_path  <- file.path(home_path, 'DERIVATIVES/FIGURES/BEHAV')
setwd(analysis_path)
#datasets dictory
data_path <- file.path(home_path,'DERIVATIVES/BEHAV')
# open datasets
PAV  <- read.delim(file.path(data_path,'PAV/OBIWAN_PAV.txt'), header = T, sep ='') #
INST <- read.delim(file.path(data_path,'INSTRU/OBIWAN_INST.txt'), header = T, sep ='') #
PIT  <- read.delim(file.path(data_path,'PIT/OBIWAN_PIT.txt'), header = T, sep ='') #
HED  <- read.delim(file.path(data_path,'HED/OBIWAN_HEDONIC.txt'), header = T, sep ='') #
info <- read.delim(file.path(analysis_path,'info_expe.txt'), header = T, sep ='') #
intern <- read.delim(file.path(analysis_path,'OBIWAN_INTERNAL.txt'), header = T, sep ='') #
info <- read.delim(file.path(data_path,'info_expe.txt'), header = T, sep ='') #
intern <- read.delim(file.path(data_path,'OBIWAN_INTERNAL.txt'), header = T, sep ='') #
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, session == 'second'))
# open datasets
PAV  <- read.delim(file.path(data_path,'OBIWAN_PAV.txt'), header = T, sep ='') #
INST <- read.delim(file.path(data_path,'OBIWAN_INST.txt'), header = T, sep ='') #
PIT  <- read.delim(file.path(data_path,'OBIWAN_PIT.txt'), header = T, sep ='') #
HED  <- read.delim(file.path(data_path,'OBIWAN_HEDONIC.txt'), header = T, sep ='') #
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, session == 'second'))
dflist <- setNames(dflist, tables)
View(HED)
dflist <- lapply(mget(tables),function(x)subset(x, session == 'second'))
View(dflist)
dflist <- setNames(dflist, tables)
View(PAV)
dflist <- lapply(mget(tables),function(x)subset(x, session == 'second'))
list2env(dflist, envir=.GlobalEnv)
View(PAV)
# themes for plots
averaged_theme <- theme_bw(base_size = 32, base_family = "Helvetica")+
theme(strip.text.x = element_text(size = 32, face = "bold"),
strip.background = element_rect(color="white", fill="white", linetype="solid"),
legend.position="none",
legend.text  = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.title.x = element_text(size = 32),
axis.title.y = element_text(size =  32),
axis.line = element_line(size = 0.5),
panel.border = element_blank())
timeline_theme <- theme_bw(base_size = 32, base_family = "Helvetica")+
theme(strip.text.x = element_text(size = 32, face = "bold"),
strip.background = element_rect(color="white", fill="white", linetype="solid"),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.text  = element_text(size =  14),
legend.title = element_text(size =  14),
axis.title.x = element_text(size = 32),
axis.title.y = element_text(size =  32),
axis.line = element_line(size = 0.5),
panel.border = element_blank())
pal = viridis::inferno(n=5)
# -------------------------------------------------------------------------------------------------
#                                             PAVLOVIAN
# -------------------------------------------------------------------------------------------------
# ---------------------------------
tables
tables[3]
tables[5] = []
tables[5] = ()
tables[-length(tables)]
tables = tables[-length(tables)]
dflist <- lapply(mget(tables),function(x)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)
View(PIT)
tables
`%notin%` <- Negate(`%in%`)
dflist <- lapply(mget(tables),function(x)filter(x, id %notin% c(242, 256, 114, 228)))
list2env(dflist, envir=.GlobalEnv)
View(PAV)
unique(PAV$ID)
unique(PAV$id)
1:4
tables
tables[i]
i = 2
i = 1
tables[i]
# creates internal states variables
for (i in 1:4){
baseINTERN = subset(intern, phase == i+1)
tables[i] = merge(x = tables[i], y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
diffINTERN = subset(intern, phase == i+1 | phase == i+2) #before and after
before = subset(diffINTERN, phase == i+1); after = subset(diffINTERN, phase == i+2); diff = after
diff$diff_piss = diff$piss - before$piss
diff$diff_thirsty = diff$thirsty - before$thirsty
diff$diff_hungry = diff$hungry - before$hungry
tables[i] = merge(x = PAV, y = diff[ , c("diff_piss", "diff_thirsty", 'diff_hungry', 'id')], by = "id", all.x=TRUE)
}
for (i in 1:4){
baseINTERN = subset(intern, phase == i+1)
tables[i] = merge(x = tables[i], y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
diffINTERN = subset(intern, phase == i+1 | phase == i+2) #before and after
before = subset(diffINTERN, phase == i+1); after = subset(diffINTERN, phase == i+2); diff = after
diff$diff_piss = diff$piss - before$piss
diff$diff_thirsty = diff$thirsty - before$thirsty
diff$diff_hungry = diff$hungry - before$hungry
tables[i] = merge(x = tables[i], y = diff[ , c("diff_piss", "diff_thirsty", 'diff_hungry', 'id')], by = "id", all.x=TRUE)
}
i = 1
baseINTERN = subset(intern, phase == i+1)
tables[i] = merge(x = tables[i], y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
tables[i]
??mget
for (i in 1:4){
baseINTERN = subset(intern, phase == i+1)
get(tables[i]) = merge(x = get(tables[i]), y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
diffINTERN = subset(intern, phase == i+1 | phase == i+2) #before and after
before = subset(diffINTERN, phase == i+1); after = subset(diffINTERN, phase == i+2); diff = after
diff$diff_piss = diff$piss - before$piss
diff$diff_thirsty = diff$thirsty - before$thirsty
diff$diff_hungry = diff$hungry - before$hungry
get(tables[i]) = merge(x = get(tables[i]), y = diff[ , c("diff_piss", "diff_thirsty", 'diff_hungry', 'id')], by = "id", all.x=TRUE)
}
get(tables[i]
)
baseINTERN = subset(intern, phase == i+1)
eval_tidy(tables[i]) = merge(x = get(tables[i]), y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
??eval_tidy
library(rlang)
baseINTERN = subset(intern, phase == i+1)
eval_tidy(tables[i]) = merge(x = get(tables[i]), y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
?rlang::eval_tidy
baseINTERN = subset(intern, phase == i+1)
eval(tables[i]) = merge(x = get(tables[i]), y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
assign(tables[i], merge(x = get(tables[i]), y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE))
tables[i]
listA <- list(matrix(rnorm(2000), nrow=10),
matrix(rnorm(2000), nrow=10))
listA
function(data,number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
return(data)
}
def = function(data,number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
return(data)
}
def('PAV', 2)
####################################################################################################
#                                                                                                  #
#                                                                                                  # #                                                                                                  #
#                                    TITLE OF THE PAPER                                            #
#                                                                                                  #
#                                                                                                  #
#                                                                                                  #
# Created by E.R.P on NOVEMBER 2018                                                               #
# modified by D.M.T. on AUGUST 2020                                                                 #
####################################################################################################
#--------------------------------------  PRELIMINARY STUFF ----------------------------------------
#load libraries
if(!require(pacman)) {
install.packages("pacman")
install.packages("devtools")
library(pacman)
}
pacman::p_load(apaTables, MBESS, afex, car, ggplot2, dplyr, plyr, tidyr,
reshape, Hmisc, Rmisc,  ggpubr, ez, gridExtra, plotrix,
lsmeans, BayesFactor, effectsize, devtools, misty)
# get tool
devtools::source_gist("2a1bb0133ff568cbe28d",
filename = "geom_flat_violin.R")
#SETUP
# Set path
home_path       <- '~/OBIWAN'
# Set working directory
analysis_path <- file.path(home_path, 'CODE/ANALYSIS/BEHAV/ForPaper')
figures_path  <- file.path(home_path, 'DERIVATIVES/FIGURES/BEHAV')
setwd(analysis_path)
#datasets dictory
data_path <- file.path(home_path,'DERIVATIVES/BEHAV')
# open datasets
PAV  <- read.delim(file.path(data_path,'OBIWAN_PAV.txt'), header = T, sep ='') #
INST <- read.delim(file.path(data_path,'OBIWAN_INST.txt'), header = T, sep ='') #
PIT  <- read.delim(file.path(data_path,'OBIWAN_PIT.txt'), header = T, sep ='') #
HED  <- read.delim(file.path(data_path,'OBIWAN_HEDONIC.txt'), header = T, sep ='') #
info <- read.delim(file.path(data_path,'info_expe.txt'), header = T, sep ='') #
intern <- read.delim(file.path(data_path,'OBIWAN_INTERNAL.txt'), header = T, sep ='') #
#subset only pretest
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, session == 'second'))
list2env(dflist, envir=.GlobalEnv)
#exclude participants (242 really outlier everywhere, 256 can't do the task, 114 & 228 REALLY hated the solution and thus didn't "do" the conditioning)
`%notin%` <- Negate(`%in%`)
dflist <- lapply(mget(tables),function(x)filter(x, id %notin% c(242, 256, 114, 228)))
list2env(dflist, envir=.GlobalEnv)
#merge with info
tables = tables[-length(tables)] # remove intern
dflist <- lapply(mget(tables),function(x)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)
listA = 2:5
listB = 3:6
dflist <- mapply(mget(tables),function(x,y,z)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)
def = function(data,number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
return(data)
}
def('PAV', 2)
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
diffINTERN = subset(intern, phase == number | phase == number+1) #before and after
before = subset(diffINTERN, phase == number); after = subset(diffINTERN, phase == number+1); diff = after
diff$diff_piss = diff$piss - before$piss
diff$diff_thirsty = diff$thirsty - before$thirsty
diff$diff_hungry = diff$hungry - before$hungry
data= merge(data, y = diff[ , c("diff_piss", "diff_thirsty", 'diff_hungry', 'id')], by = "id", all.x=TRUE)
return(data)
}
def('PAV', 2)
listA = 2:5
mapply(def,mget(tables),listA)
mapply(def,tables,listA)
lst = mapply(def,tables,listA)
View(lst)
listA = 2:5
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("piss", "thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
diffINTERN = subset(intern, phase == number | phase == number+1) #before and after
before = subset(diffINTERN, phase == number); after = subset(diffINTERN, phase == number+1); diff = after
diff$diff_piss = diff$piss - before$piss
diff$diff_thirsty = diff$thirsty - before$thirsty
diff$diff_hungry = diff$hungry - before$hungry
data= merge(data, y = diff[ , c("diff_piss", "diff_thirsty", 'diff_hungry', 'id')], by = "id", all.x=TRUE)
return(data)
}
dflist = mapply(def,tables,listA)
list2env(dflist, envir=.GlobalEnv)
View(PIT)
fac <- c("id", "trial", "condition", "group" ,"trialxcondition", "gender")
PAV[fac] <- lapply(PAV[fac], factor)
PAV$RT               <- PAV$RT * 1000
#Preprocessing
PAV.clean$condition <- droplevels(PAV.clean$condition, exclude = "Baseline")
full = length(PAV.clean$RT)
##shorter than 100ms and longer than 3sd+mean
PAV.clean <- filter(PAV.clean, RT >= 100) # min RT is
PAV$RT               <- PAV$RT * 1000
#Preprocessing
PAV$condition <- droplevels(PAV$condition, exclude = "Baseline")
full = length(PAV$RT)
Levels(PAV$condition)
levels(PAV$condition)
PAV.clean <- filter(PAV, RT >= 100) # min RT is
PAV.clean <- ddply(PAV.clean, .(id), transform, RTm = mean(RT))
PAV.clean <- ddply(PAV.clean, .(id), transform, RTsd = sd(RT))
PAV.clean <- filter(PAV.clean, RT <= RTm+3*RTsd)
# calculate the dropped data in the preprocessing
clean= length(PAV.clean$RT)
dropped = full-clean
(dropped*100)/full
densityPlot(PAV.clean$RT) #skewed bwaaa
acc_bef = mean(PAV$ACC, na.rm = TRUE) #0.93
acc_bef
#log transform function
t_log_scale <- function(x){
if(x==0){y <- 1}
else {y <- (sign(x)) * (log(abs(x)))}
y }
PAV$RT_T <- sapply(PAV$RT,FUN=t_log_scale)
densityPlot(PAV$RT_T) # ahh this is much better !
# get times in milliseconds
PAV$RT               <- PAV$RT * 1000
#Preprocessing
PAV$condition <- droplevels(PAV$condition, exclude = "Baseline")
acc_bef = mean(PAV$ACC, na.rm = TRUE) #0.93
full = length(PAV$RT)
##shorter than 100ms and longer than 3sd+mean
PAV.clean <- filter(PAV, RT >= 100) # min RT is
PAV.clean <- ddply(PAV.clean, .(id), transform, RTm = mean(RT))
PAV.clean <- ddply(PAV.clean, .(id), transform, RTsd = sd(RT))
PAV.clean <- filter(PAV.clean, RT <= RTm+3*RTsd)
# calculate the dropped data in the preprocessing
clean= length(PAV.clean$RT)
dropped = full-clean
(dropped*100)/full
densityPlot(PAV.clean$RT) #skewed
#log transform function
t_log_scale <- function(x){
if(x==0){y <- 1}
else {y <- (sign(x)) * (log(abs(x)))}
y }
PAV$RT_T <- sapply(PAV$RT,FUN=t_log_scale)
densityPlot(PAV$RT_T) # ahh this is much better !
PAV.clean$RT_T <- sapply(PAV.clean$RT,FUN=t_log_scale)
densityPlot(PAV.clean$RT_T) # ahh this is much better !
densityPlot(PAV.clean$RT) #skewed
#log transform function
t_log_scale <- function(x){
if(x==0){y <- 1}
else {y <- (sign(x)) * (log(abs(x)))}
y }
PAV.clean$RT_T <- sapply(PAV.clean$RT,FUN=t_log_scale)
densityPlot(PAV.clean$RT_T) # much better !
# get times in milliseconds
PAV$RT               <- PAV$RT * 1000
#Preprocessing
PAV$condition <- droplevels(PAV$condition, exclude = "Baseline")
acc_bef = mean(PAV$ACC, na.rm = TRUE) #0.93
full = length(PAV$RT)
##shorter than 100ms and longer than 3sd+mean
PAV.clean <- filter(PAV, RT >= 100) # min RT is
PAV.clean <- ddply(PAV.clean, .(id), transform, RTm = mean(RT))
PAV.clean <- ddply(PAV.clean, .(id), transform, RTsd = sd(RT))
PAV.clean <- filter(PAV.clean, RT <= RTm+3*RTsd)
# calculate the dropped data in the preprocessing
clean= length(PAV.clean$RT)
dropped = full-clean
(dropped*100)/full
densityPlot(PAV.clean$RT) #skewed
#log transform function
t_log_scale <- function(x){
if(x==0){y <- 1}
else {y <- (sign(x)) * (log(abs(x)))}
y }
PAV.clean$RT_T <- sapply(PAV.clean$RT,FUN=t_log_scale)
densityPlot(PAV.clean$RT_T) # muc
sapply(PAV.clean$RT,FUN=t_log_scale)
densityPlot(PAV.clean$RT) #skewed
PAV.clean$liking
# -------------------------------------- STATS -----------------------------------------------
PAV.means <- aggregate(PAV.clean$RT, by = list(PAV.clean$id, PAV.clean$condition, PAV.clean$liking_ratings), FUN='mean') # extract means
colnames(PAV.means) <- c('id','condition','liking','RT')
PAV.means <- aggregate(PAV.clean$RT, by = list(PAV.clean$id, PAV.clean$condition, PAV.clean$liking_ratings), FUN='mean') # extract means
PAV.clean$id
PAV.means <- aggregate(PAV.clean$RT, by = list(PAV.clean$id, PAV.clean$condition, PAV.clean$likin), FUN='mean') # extract means
colnames(PAV.means) <- c('id','condition','liking','RT')
PAV.means <- aggregate(PAV.clean$RT, by = list(PAV.clean$id, PAV.clean$condition, PAV.clean$liking, PAV.clean$group), FUN='mean') # extract means
PAV.means
colnames(PAV.means) <- c('id','condition','liking','group', 'RT')
anova.RT <- aov_car(RT ~ condition*group + Error (id/condition), data = PAV.means, anova_table = list(correction = "GG", es = "pes"))
options(contrasts())
options(contrasts
)
options(contrasts =contrasts()
)]
options(contrasts = rep("contr.sum", 2))
anova.RT <- aov_car(RT ~ condition*group + Error (id/condition), data = PAV.means, anova_table = list(correction = "GG", es = "pes"))
anova.RT
source('~/OBIWAN/CODE/ANALYSIS/BEHAV/R_functions/pes_ci.R', echo=TRUE)
pes_ci(RT ~ condition*group + Error (id/condition), PAV.means)
# Bayes factors
RT.BF <- anovaBF(RT ~ condition *group  + id, data = PAV.means,
whichRandom = "id", iterations = 50000); RT.BF
